# -*- coding: utf-8 -*-
"""Proyecto

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/175o-2viQ5571edB9P-BHId-g5onpE9rH
"""

#Implementación basada en el paper basde del proyecto


#Descargando el Dataset de Kaggle

from google.colab import files
files.upload()  #this will prompt you to upload the kaggle.json

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!ls ~/.kaggle
!chmod 600 /root/.kaggle/kaggle.json  # set permission

! kaggle datasets download -d jessicali9530/celeba-dataset


! unzip  celeba-dataset.zip  -d kaggle

! unzip  kaggle/img_align_celeba.zip  -d kaggle

from google.colab import drive
drive.mount('/content/drive')

! ls kaggle/img_align_celeba | wc -l

!nvidia-smi

!pip3 install torch==1.1
!pip3 install torchvision==0.3.0
!pip3 install Pillow==4.3
!pip3 install scipy
!pip3 install numpy
!pip3 install matplotlib

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from torch.autograd.variable import Variable
import torch.nn.functional as F
import numpy as np
import os

# PARAMETROS

BATCH_SIZE = 20
NUM_EPOCH = 5 #Número de epocas
LEARNING_RATE_G = 0.0002 #Ratio de aprendizaje del autoencoder
LEARNING_RATE_D = 0.0002 #Rario de aprendizaje del discriminador
CUDA = True #Para usar GPU (True) o CPU(False)
OUTPUT_PATH = 'output/dae_gan' #Carpeta de salida
MODEL_PATH = 'model/dae_gan' # Ubicación para guardar el modelo

# Configuración
device = torch.device('cuda' if torch.cuda.is_available() and CUDA else 'cpu')
if not os.path.exists(OUTPUT_PATH): os.makedirs(OUTPUT_PATH)
if not os.path.exists(MODEL_PATH): os.makedirs(MODEL_PATH)

#Preparación del Dataset
xform = transforms.Compose([
    torchvision.transforms.Resize([128,128]),
    transforms.ToTensor()
])
#Leer el Dataset 

dset = torchvision.datasets.ImageFolder('kaggle', transform=xform)


# Separar el dataset 50 % para entrenamiento y 50% para pruebas
train_size = int(0.5 * len(dset))
test_size = len(dset) - train_size

train_dataset, eval_dataset = torch.utils.data.random_split(dset, [train_size, test_size])

#Creación del data Loader
train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)

eval_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False)

print('# Entrenamiento: {}'.format(len(train_dataset)))
print('# Pruebas : {}'.format(len(eval_dataset)))

    
dataiter = iter(train_loader)
img, _ = dataiter.next()

#Autoencoder 

class AutoEncoder(nn.Module):
    def __init__(self):
        super(AutoEncoder, self).__init__()
        n_features = 128
        n_out = 128
        
        self.hidden0 = nn.Sequential(
            nn.Linear(n_features, 256),
            nn.LeakyReLU(0.2)
        )
        self.hidden1 = nn.Sequential(    
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2)
        )
        self.hidden2 = nn.Sequential(
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2)
        )
        
        self.out = nn.Sequential(
            nn.Linear(1024, n_out),
            nn.Tanh()
        )

    def forward(self, x):
        x = self.hidden0(x)
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.out(x)
        return x

#Discriminador
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        n_features = 128
        n_out = 128
        
        self.hidden0 = nn.Sequential( 
            nn.Linear(n_features, 1024),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3)
        )
        self.hidden1 = nn.Sequential(
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
        )
        self.hidden2 = nn.Sequential(
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
        )
        self.out = nn.Sequential(
            torch.nn.Linear(256, n_out),
            torch.nn.Sigmoid()
        )

    def forward(self, x):
        x = self.hidden0(x)
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.out(x)
        return x

#Función de perdida para el discriminador
class GANLoss(nn.Module):
    def __init__(self):
        super(GANLoss, self).__init__()
        self.REAL_LABEL=1.0
        self.FAKE_LABEL=0.0
        self.fake_cache = None
        self.real_cache = None
        self.discriminator_loss = nn.BCELoss()
        
    def __call__(self, x, isreal):
        if isreal:
            if (self.real_cache is None) or (x.numel() != self.real_cache.numel()):
                self.real_cache = x.new_full(x.size(), self.REAL_LABEL, requires_grad=False)
                self.real_cache.to(x.device)
            target = self.real_cache
        else:
            if (self.fake_cache is None) or (x.numel() != self.fake_cache.numel()):
                self.fake_cache = x.new_full(x.size(), self.FAKE_LABEL, requires_grad=False)
                self.fake_cache.to(x.device)
            target = self.fake_cache

        return self.discriminator_loss(x, target)

# Creación del Denoising Autoencoder , optimizador y funciones de perdida 
G = AutoEncoder().to(device)
D = Discriminator().to(device)
optimizer_g = torch.optim.Adam(G.parameters(), lr=LEARNING_RATE_G)
optimizer_d = torch.optim.Adam(D.parameters(), lr=LEARNING_RATE_D)
reconstruction_loss = nn.MSELoss()
gan_loss = GANLoss()

# Función de entrenamiento
# Este metodo es llamado para cada epoca con su respectivo ID
# Retorna el promedio de perdida del entrenamiento para el autoencoder y el discriminador.

def train(epoch):
    G.train()
    D.train()
    total_g_loss = 0.0
    total_d_loss = 0.0
    for i, (img, _) in enumerate(train_loader):
        
        
        noise = torch.randn(img.size()) * 0.2
        noisy_img = img + noise
  
        
        noisy_img = Variable(noisy_img).cuda()
        img = Variable(img).cuda()
        # Forward de Autoencoder 
        output = G(noisy_img)
        # Forward del discriminador 
        
        
        optimizer_d.zero_grad()

        d_prediction_real = D(img)
        d_error_real = gan_loss(d_prediction_real, 1 )
        
        d_prediction_fake = D(output)
        d_error_fake = gan_loss(d_prediction_fake, 0 )
        
        d_loss = (0.5 * d_error_real) + (0.5 * d_error_fake)
        d_loss.backward(retain_graph=True)
        optimizer_d.step()
        

        
        optimizer_g.zero_grad()
        g_prediction_fake = D(output)
        error = reconstruction_loss(output, img)
        g_error_fake = gan_loss(d_prediction_fake, 0 )
        
        g_loss = (0.995 * error) + (0.005 * g_error_fake) 
        g_loss.backward()
        optimizer_g.step()
        

        # Actualizando Perdida
        total_d_loss = total_d_loss + d_loss.item()
        total_g_loss = total_g_loss + g_loss.item()
        
        # Impimiendo  para el entrenamiento
        if i % 50 == 0:
            print('[{0:3d}/{1}] {2:3d}/{3} loss_g: {4:.4f} | loss_d: {5:4f}'
                .format(epoch+1, NUM_EPOCH, i+1, len(train_loader), g_loss.item(), d_loss.item()))

        #generar y guardar imagenes de salida
        if i % 100 == 0:
            out = torch.cat([noisy_img, img, output], dim=3).detach().cpu().clamp(0.0, 1.0)
            vutils.save_image(out, '{}/{}_output.png'.format(OUTPUT_PATH, epoch, i), normalize=True)
            vutils.save_image(out, '{}/{}_{}.png'.format(OUTPUT_PATH, epoch, i), normalize=True)
            #show(out)
    
    #Guardando los pesos
    if (epoch + 1) % 10 == 0:
        save_dict = {
            'g':G.state_dict(), 
            'g_optim':optimizer_g.state_dict(),
            'd': D.state_dict(),
            'd_optim': optimizer_d.state_dict()
        }
        torch.save(save_dict, '{}/dae_gan_{}.pth.tar'.format(MODEL_PATH, epoch+1))
    
    #Calculando la perdida promedio para la epoca actual
    avg_g_loss = total_g_loss / len(train_loader)
    avg_d_loss = total_d_loss / len(train_loader)
    print('Epoch[{}] Training Loss G: {:4f} | D: {:4f}'.format(epoch+1, avg_g_loss, avg_d_loss))
    
    return avg_g_loss, avg_d_loss

# Función de evaluación
#Este metodo es llamado en cada epoca con su respectivo ID
# Retorna la perdida promedio para el autoencoder y el discriminador

def evaluate(epoch):
    with torch.no_grad():
      G.eval()
      D.eval()
      total_g_loss = 0.0
      total_d_loss = 0.0
      for i, (img, _) in enumerate(eval_loader):
          
          noise = torch.randn(img.size()) * 0.2
          noisy_img = img + noise

          noisy_img = Variable(noisy_img).cuda()
          img = Variable(img).cuda()

          # Forward del Autoencoder
          output = G(noisy_img)

          # Forward del discriminador
          optimizer_d.zero_grad()

          d_prediction_real = D(img)
          d_prediction_fake = D(output)

          #Calculan el error del discriminador
          d_error_real = gan_loss(d_prediction_real, 1 )
          d_error_fake = gan_loss(d_prediction_fake, 0 )
          d_loss = (0.5 * d_error_real) + (0.5 * d_error_fake)

          # Se calcula el error del autoencoder
          optimizer_g.zero_grad()
          g_prediction_fake = D(output)
          error = reconstruction_loss(output, img)
          g_error_fake = gan_loss(d_prediction_fake, 0 )

          g_loss = (0.995 * error) + (0.005 * g_error_fake) 

          #Actualizando el valor de las perdidas
          total_d_loss = total_d_loss + d_loss.item()
          total_g_loss = total_g_loss + g_loss.item()

      avg_g_loss = total_g_loss / len(eval_loader)
      avg_d_loss = total_d_loss / len(eval_loader)
      print('Epoch[{}] Evaluation Loss G: {:4f} | D: {:4f}'.format(epoch+1, avg_g_loss, avg_d_loss))

      return avg_g_loss, avg_d_loss

cache_train_g = []
cache_eval_g = []
cache_train_d = []
cache_eval_d = []

for epoch in range(NUM_EPOCH):
    #Entrenamiento y pruebas
    avg_train_g_loss, avg_train_d_loss = train(epoch)
    avg_eval_g_loss, avg_eval_d_loss = evaluate(epoch)
    
    #Guardar los valores de entrenamiento y pruebas para graficarlos
    cache_train_g.append(avg_train_g_loss)
    cache_eval_g.append(avg_eval_g_loss)
    cache_train_d.append(avg_train_d_loss)
    cache_eval_d.append(avg_eval_d_loss)

#Mostrando gráfico de Perdida del autoencoder /Entrenamiento Vs Test 
plt.plot(
    cache_train_g, 'r', 
    cache_eval_g, 'b')
plt.title('Autoencoder Loss')
plt.ylabel('Perdida')
plt.xlabel('Epocas')
plt.legend(['Entrenamiento','Test'])
plt.show()

#Mostrando gráfico de Perdida del Discriminador /Entrenamiento Vs Test 
plt.plot(
    cache_train_d, 'r', 
    cache_eval_d, 'b')
plt.title('Discriminador Loss')
plt.ylabel('Perdida')
plt.xlabel('Epoca')
plt.legend(['Entrenamiento','Test'])
plt.show()

#RESULTADOS 
#PRIMERA IMAGEN : imagen generada con ruido aleatorio
#SEGUNDA IMAGEN : imagen original
#TERCERA IMAGEN :imagen recuperada
from skimage import io

image = io.imread(OUTPUT_PATH + '/4_500.png')
plt.figure(figsize=(40,40))
plt.imshow(image)

import numpy as np
import cv2
from matplotlib import pyplot as plt

cap = cv2.VideoCapture('vtest.avi')


img = [cap.read()[1] for i in xrange(5)]

gray = [cv2.cvtColor(i, cv2.COLOR_BGR2GRAY) for i in img]

gray = [np.float64(i) for i in gray]

noise = np.random.randn(*gray[1].shape)*10

noisy = [i+noise for i in gray]


noisy = [np.uint8(np.clip(i,0,255)) for i in noisy]


dst = cv2.fastNlMeansDenoisingMulti(noisy, 2, 5, None, 4, 7, 35)
plt.subplot(131),plt.imshow(gray[2],'gray')
plt.subplot(132),plt.imshow(noisy[2],'gray')
plt.subplot(133),plt.imshow(dst,'gray')
plt.show()

